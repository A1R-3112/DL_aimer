{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Info WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import platform\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,  DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('dark_background')                # 그래프 배경 색상 변경\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family = 'AppleGothic')              # 한글폰트 깨짐현상 제거\n",
    "else:\n",
    "    rc('font', family = 'NanumGothic')\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'  # 그래프 고해상도로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + '/data/'\n",
    "df_brand = pd.read_csv(PATH + 'brand_keyword_cnt.csv')\n",
    "pd_info = pd.read_csv(PATH + 'product_info.csv')\n",
    "sales = pd.read_csv(PATH + 'sales.csv')\n",
    "df_smp = pd.read_csv(PATH + 'sample_submission.csv')\n",
    "df_train = pd.read_csv(PATH + 'train.csv')\n",
    "smp = train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = list(df_train.제품)\n",
    "product_id = list(pd_info.제품)\n",
    "\n",
    "cnt = 0\n",
    "no_pd = []\n",
    "yes_pd = []\n",
    "for t in train_id:\n",
    "    if t in product_id:\n",
    "        cnt += 1\n",
    "        yes_pd.append(t)\n",
    "    else:\n",
    "        no_pd.append(t)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "no = []\n",
    "yes = []\n",
    "for p in product_id:\n",
    "    if p in train_id:\n",
    "        cnt += 1\n",
    "        yes.append(p)\n",
    "    else:\n",
    "        no.append(p)\n",
    "print(cnt)\n",
    "print(no[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for y in yes:\n",
    "    if y in yes_pd:\n",
    "        cnt += 1\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(len(yes) == cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic_info = {}\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "    dic[i] = df_train.loc[i, '제품']\n",
    "print(len(dic.keys()))\n",
    "\n",
    "for i in range(pd_info.shape[0]):\n",
    "    dic_info[i] = pd_info.loc[i, '제품']\n",
    "print(len(dic_info.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_copy = dic.copy()\n",
    "info_copy = dic_info.copy()\n",
    "dic_yes = {}\n",
    "\n",
    "for k, v in dic_copy.items():\n",
    "    if v in yes:\n",
    "        cnt += 1\n",
    "        dic_yes[k] = v\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for k, v in info_copy.items():\n",
    "    if v not in yes:\n",
    "        del dic_info[k]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(dic_yes.keys())\n",
    "info_train = df_train.loc[id_list, :]\n",
    "\n",
    "info_id = list(dic_info.keys())\n",
    "info_df = pd_info.loc[info_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(info_train.iloc[:, 0:6], info_df)\n",
    "df_merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_class = list(df_merge.대분류.value_counts().keys())\n",
    "major_class # 대분류 코드 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_1 = df_merge[df_merge.대분류 == major_class[0]]\n",
    "major_2 = df_merge[df_merge.대분류 == major_class[1]]\n",
    "major_3 = df_merge[df_merge.대분류 == major_class[2]]\n",
    "major_4 = df_merge[df_merge.대분류 == major_class[3]]\n",
    "major_5 = df_merge[df_merge.대분류 == major_class[4]]\n",
    "\n",
    "major_list = [major_1, major_2, major_3, major_4, major_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('jhgan/ko-sroberta-multitask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(major_class):\n",
    "    major_class['제품특성'] = major_class['제품특성'] \\\n",
    "        .replace(r'[^가-힣 ]', ' ', regex=True) \\\n",
    "        .replace(\"'\", '') \\\n",
    "        .replace(r'\\s+', ' ', regex=True) \\\n",
    "        .str.strip() \\\n",
    "        .str[:255]\n",
    "    \n",
    "    return major_class['제품특성']\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split(' ')\n",
    "    stops = '특징'\n",
    "\n",
    "    meaningful_words = [w for w in tokens if stops not in w]\n",
    "    return ' '.join(meaningful_words)\n",
    "\n",
    "for major in major_list:\n",
    "    major['제품특성'] = preprocessing(major).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(df_merge.제품특성)\n",
    "info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['제품특성'] = preprocessing(info).apply(remove_stopwords)\n",
    "info_corpus = info['제품특성'].values.tolist()\n",
    "len(info_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_embeddings = model.encode(info_corpus)\n",
    "corpuses = [major['제품특성'].values.tolist() for major in major_list]\n",
    "len(corpuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for corpus in corpuses:\n",
    "    embeddings.append(model.encode(corpus))\n",
    "\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(embeddings, corpus):\n",
    "    num_clusters = 8\n",
    "    clustering_model = KMeans(n_clusters=num_clusters)\n",
    "    clustering_model.fit(embeddings)\n",
    "    cluster_assignment = clustering_model.labels_\n",
    "\n",
    "    clustered_sentences = [[] for i in range(num_clusters)]\n",
    "    for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "        clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "    for i, cluster in enumerate(clustered_sentences):\n",
    "        print('Cluster %d (%d)' % (i+1, len(cluster)))\n",
    "        print(cluster)\n",
    "        print('')\n",
    "\n",
    "    return clustered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering(embeddings[1], corpuses[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clustering(info_embeddings, info_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran, Okt, Kkma, Hannanum\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "rc('font', family = 'AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "cnt = 1\n",
    "for major in major_list:\n",
    "    fig = plt.figure(figsize=(8, 4), facecolor= 'black')\n",
    "\n",
    "    extractor = Hannanum()\n",
    "\n",
    "    nouns = []\n",
    "\n",
    "    for f in major['제품특성'].values.tolist():\n",
    "        nouns.extend(extractor.nouns(f))\n",
    "\n",
    "    count = Counter(nouns)\n",
    "    words = dict(count.most_common())\n",
    "\n",
    "    for i, (word, count) in enumerate(words.items()):\n",
    "        if i > 5:\n",
    "            break\n",
    "        print(word, count)\n",
    "        \n",
    "    wc = WordCloud(\n",
    "        font_path='/Users/a1r/Library/Fonts/NanumMyeongjo.ttf',\n",
    "        width=2000,\n",
    "        height=1000\n",
    "    ).generate_from_frequencies(words)\n",
    "    \n",
    "    plt.title(f'[{cnt} Cluster]', color = 'white')\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
