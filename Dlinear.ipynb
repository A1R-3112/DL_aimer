{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'TRAIN_WINDOW_SIZE':90, # 90일치로 학습\n",
    "    'PREDICT_SIZE':21, # 21일치 예측\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':1e-6,\n",
    "    'BATCH_SIZE':64,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADPATH = '/home/a1r/바탕화면/DL/timeseries_new_data/'\n",
    "PATH = os.getcwd() + '/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Features\n",
    "#### New_Train : train_data after feature engineering\n",
    "O : 학습에 사용될 Features\n",
    "X : 학습에서 drop할 Features\n",
    "\n",
    "* [O] sales - 제품의 일별 판매량  => **Target**\n",
    "* [X] ID - 제품 ID\n",
    "* [X] 제품 - 제품 코드\n",
    "* [O] 대분류 - 제품의 대분류\n",
    "* [O] 중분류 - 제품의 중분류\n",
    "* [O] 소분류 - 제품의 소분류\n",
    "* [O] 브랜드 - 제품의 브랜드\n",
    "* [X] date - 제품의 판매 날짜\n",
    "    *  `23.02.23 ~ 23.03.28` : 약 92.65%의 상품이 이 기간동안 0임을 알 수 있음\n",
    "* [O] quarter - 제품의 판매 분기 (1, 2, 3, 4)분기 존재\n",
    "* [O] day_name - 제품의 판매 요일\n",
    "* [O] keyword - 정규화된 제품 브랜드의 키워드 언급 횟수 : 브랜드의 인지도로 판단\n",
    "* [O] price - 제품의 판매 가격(₩)\n",
    "* [O] event - 해당 날짜에 event가 있음 (binary? or Category?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.read_csv(LOADPATH + 'train_fe.csv', low_memory=False)\n",
    "new_train = new_train.sort_values(by = ['ID', 'date']).reset_index(drop = True)\n",
    "origin_train = pd.read_csv(PATH + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8189657f0fe64d14a124d0a62eda5764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>day_name</th>\n",
       "      <th>quarter</th>\n",
       "      <th>keyword</th>\n",
       "      <th>event</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>1.45053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID             대분류             중분류             소분류         브랜드  day_name  \\\n",
       "0   0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001  Saturday   \n",
       "1   0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001    Sunday   \n",
       "2   0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001    Monday   \n",
       "\n",
       "   quarter  keyword  event  sales        date  \n",
       "0        1  0.84131      1      0  2022-01-01  \n",
       "1        1  0.91383      0      0  2022-01-02  \n",
       "2        1  1.45053      0      0  2022-01-03  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_FE(df):\n",
    "    one = df.query('event != \"0\"')\n",
    "    one.event = np.ones(len(one), dtype = np.int16)\n",
    "    df.loc[one.index, 'event'] = one.event\n",
    "    df.event = df.event.astype(np.int16)\n",
    "\n",
    "    drop_date = []\n",
    "    df_enc = df.copy()\n",
    "    columns = ['ID', '대분류', '중분류', '소분류', '브랜드', 'day_name', 'quarter', 'keyword', 'event', 'sales', 'date']\n",
    "\n",
    "    for i in range(34):\n",
    "        drop_date.append(list(np.array(pd.date_range('2023-02-23', periods = 34)).astype(str))[i].split('T')[0])\n",
    "\n",
    "    for date in tqdm(drop_date):\n",
    "        drop_idx = df_enc.query('date == @date').index\n",
    "        df_enc.drop(drop_idx, axis = 0, inplace = True)\n",
    "\n",
    "    df_enc.drop(['제품','year', 'month', 'day', 'day_of_week', 'price'], axis = 1, inplace = True)\n",
    "    df_enc = df_enc[columns]\n",
    "    df_enc = df_enc.drop_duplicates()\n",
    "    df_enc = df_enc.reset_index(drop = True)\n",
    "\n",
    "    return df_enc\n",
    "\n",
    "train_enc = data_FE(new_train)\n",
    "train_enc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>day_name</th>\n",
       "      <th>quarter</th>\n",
       "      <th>keyword</th>\n",
       "      <th>event</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.45053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  대분류  중분류  소분류  브랜드  day_name  quarter  keyword  event  sales  \\\n",
       "0   0    1    6   37    0         2        1  0.84131      1      0   \n",
       "1   0    1    6   37    0         3        1  0.91383      0      0   \n",
       "2   0    1    6   37    0         1        1  1.45053      0      0   \n",
       "\n",
       "         date  \n",
       "0  2022-01-01  \n",
       "1  2022-01-02  \n",
       "2  2022-01-03  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding\n",
    "\n",
    "col = ['대분류', '중분류', '소분류', '브랜드', 'day_name']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for c in col:\n",
    "    train_enc[c] = encoder.fit_transform(train_enc[c])\n",
    "\n",
    "train_enc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset use base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  시간이 너무 오래걸림\n",
    "## 현실적으로 쓸 수 없는 함수\n",
    "## pandas 라이브러리가 너무 무거운 거로 판단됨 -> numpy 데이터로 변형 후 함수 적용하는게 맞는듯\n",
    "## numpy로 바꿔도 차이가 없음 : 시간복잡도가 너무 높아서 생기는 문제로 판단됨 O(n^2)\n",
    "## pandas.DataFrame.query()의 문제라고 판명\n",
    "## ID및 date의 순서로 되어있기 때문에 iloc을 사용해 순서대로 잘라서 dataset을 만들어서 작업 소요시간이 매우 줄음\n",
    "\n",
    "def make_train_data(data, train_size = CFG['TRAIN_WINDOW_SIZE'], predict_size = CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : date를 melt시킨 새로운 train data\n",
    "    train_size : 학습에 활용할 기간 => 90 Days\n",
    "    predict_size : 추론할 기간 => 21 Days\n",
    "    '''\n",
    "    window_size = train_size + predict_size         # 90 + 21 = 111\n",
    "    num_id = data.ID.nunique()                      # 15890\n",
    "    num_date = data.date.nunique()                  # 425\n",
    "    num_features = len(data.iloc[0, 1:9])           # 대분류 ~ sales까지\n",
    "    data = np.array(data)                           # DataFrame to Numpy Data\n",
    "    \n",
    "    input_data = np.empty((num_id * ((num_date + num_features) - window_size + 1), train_size, num_features + 1), dtype = np.float16)\n",
    "    target_data = np.empty((num_id * ((num_date + num_features) - window_size + 1), predict_size), dtype = np.float16)\n",
    "\n",
    "    for id in tqdm(range(num_id)):\n",
    "        for j in range(num_date - window_size + 1):      # 315\n",
    "            temp_data = data[id*425: 425*(id+1)][j:train_size+j, 1:10]\n",
    "            input_data[id * ((num_date + num_features) - window_size + 1) + j] = temp_data\n",
    "            target_data[id * ((num_date + num_features) - window_size + 1) + j] = data[id*425: 425*(id+1)][train_size+j:window_size+j, 9] # sales\n",
    "\n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']): #90\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : date를 melt시킨 새로운 train data\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_id = data.ID.nunique()\n",
    "    num_date = data.date.nunique()\n",
    "    num_features = data.iloc[0:1, 1:9].shape[1]   # 대분류 ~ sales까지\n",
    "    data = np.array(data)\n",
    "    \n",
    "    test_input = np.empty((num_id, train_size, num_features + 1), dtype = np.float16)\n",
    "\n",
    "    for id in tqdm(range(num_id)):\n",
    "        temp_data = data[id*425: 425*(id+1)][-train_size:, 1:10]\n",
    "        test_input[id] = temp_data\n",
    "\n",
    "    return test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = make_train_data(train_enc)\n",
    "test_input = make_predict_data(train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(PATH + 'train_input', train_input)\n",
    "# np.save(PATH + 'train_target', train_target)\n",
    "# np.save(PATH + 'test_input', test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Trainset use Time_slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d774cd56e04f64a7d437aa368d760d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def train_test_split(df):\n",
    "# list(np.array(pd.date_range('2023-02-23', periods = 34)))\n",
    "\n",
    "test_df_enc = train_enc[-1:-2]\n",
    "test_date = train_enc[train_enc.ID == 0][-91:-1].date.to_list()\n",
    "\n",
    "for date in tqdm(test_date):\n",
    "    test_smp = train_enc.query('date == @date')\n",
    "    test_df_enc = pd.concat([test_df_enc, test_smp])\n",
    "\n",
    "train_df_enc = train_enc.drop(test_df_enc.index, axis = 0).reset_index(drop = True)\n",
    "test_df_enc = test_df_enc.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 90\n",
    "forcast_size = 21\n",
    "date = 'date'\n",
    "target = 'sales'\n",
    "\n",
    "def target_standardization(train_df, test_df, target):\n",
    "    train_df_ = train_df.copy()\n",
    "    test_df_ = test_df.copy()\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "\n",
    "\n",
    "    mean, std = np.mean(list(train_df_enc[target])), np.std(list(train_df_enc[target]))\n",
    "\n",
    "    train_df_.loc[:, target] = (train_df_[target] - mean) / std\n",
    "    test_df_.loc[:, target] = (test_df_[target] - mean) / std\n",
    "    return train_df_, test_df_, mean, std\n",
    "\n",
    "\n",
    "def time_slide_df(df, window_size, forcast_size, date, target):\n",
    "    df_ = df.copy()\n",
    "    data_list = []\n",
    "    dap_list = []\n",
    "    date_list = []\n",
    "\n",
    "    for idx in tqdm(range(0, df_.shape[0]-window_size-forcast_size+1)):\n",
    "        x = df_.loc[idx:idx+window_size-1, target].values.reshape(window_size, 1)       # 90일치 판매량\n",
    "        y = df_.loc[idx+window_size:idx+window_size+forcast_size-1, target].values      # 21일치 판매량 (target)\n",
    "        date_ = df_.loc[idx+window_size:idx+window_size+forcast_size-1, date].values    # 날짜\n",
    "        data_list.append(x)\n",
    "        dap_list.append(y)\n",
    "        date_list.append(date_)\n",
    "\n",
    "    return np.array(data_list, dtype='float16'), np.array(dap_list, dtype='float16'), np.array(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1353f43e61942cd8ba04990a1940a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5323040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_enc, test_df_enc, mean_, std_ = target_standardization(train_df_enc, test_df_enc, target)\n",
    "train_input, train_target, test_date = time_slide_df(train_df_enc, window_size, forcast_size, date, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(data, train_size=CFG['TRAIN_WINDOW_SIZE'], predict_size=CFG['PREDICT_SIZE']):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 학습에 활용할 기간 => 90 Days\n",
    "    predict_size : 추론할 기간 => 21 Days\n",
    "    '''\n",
    "    num_rows = len(data) # 15890\n",
    "    window_size = train_size + predict_size # 90 + 21 = 111\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, len(data.iloc[0, :4]) + 1), dtype = np.float16)\n",
    "    # (5609170, 90, 5)\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size), dtype = np.float16)\n",
    "    # (5640950, 21)\n",
    "\n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])  # Label: 대분류, 중분류, 소분류, 브랜드\n",
    "        sales_data = np.array(data.iloc[i, 4:]) # 날짜 데이터: 2022-01-01 ~ 2023-04-04\n",
    "        \n",
    "        for j in range(len(sales_data) - window_size + 1): # 0 ~ 348\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "    \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_data(data, train_size=CFG['TRAIN_WINDOW_SIZE']): #90\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    \n",
    "    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :4]) + 1), dtype = np.float16)\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, -train_size:])\n",
    "        \n",
    "        window = sales_data[-train_size : ]\n",
    "        temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "        input_data[i] = temp_data\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualMinMaxScaler:\n",
    "    def __get_min_val(self, df, date_cols):\n",
    "        df_mins = df[date_cols].min(axis=1).to_numpy()\n",
    "        return df_mins\n",
    "\n",
    "    def __get_max_val(self, df, date_cols):\n",
    "        df_maxs = df[date_cols].max(axis=1).to_numpy()\n",
    "        return df_maxs\n",
    "\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        date_cols = [col for col in df.columns  # 일자 변수들만 Scale하기\n",
    "                     if col.startswith(\"2\")]\n",
    "\n",
    "        self.min_val = self.__get_min_val(df, date_cols)\n",
    "        self.max_val = self.__get_max_val(df, date_cols)\n",
    "        denom = self.max_val - self.min_val\n",
    "        self.denom = np.where(denom==0, 1, denom)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        date_cols = [col for col in df.columns\n",
    "                     if col.startswith(\"2\")]\n",
    "        return df[date_cols] \\\n",
    "            .apply(lambda x: (x-self.min_val)/self.denom)\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>2022-01-01</th>\n",
       "      <th>2022-01-02</th>\n",
       "      <th>2022-01-03</th>\n",
       "      <th>2022-01-04</th>\n",
       "      <th>2022-01-05</th>\n",
       "      <th>2022-01-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-26</th>\n",
       "      <th>2023-03-27</th>\n",
       "      <th>2023-03-28</th>\n",
       "      <th>2023-03-29</th>\n",
       "      <th>2023-03-30</th>\n",
       "      <th>2023-03-31</th>\n",
       "      <th>2023-04-01</th>\n",
       "      <th>2023-04-02</th>\n",
       "      <th>2023-04-03</th>\n",
       "      <th>2023-04-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B002-C001-0002</td>\n",
       "      <td>B002-C002-0007</td>\n",
       "      <td>B002-C003-0038</td>\n",
       "      <td>B002-00001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002-C001-0003</td>\n",
       "      <td>B002-C002-0008</td>\n",
       "      <td>B002-C003-0044</td>\n",
       "      <td>B002-00002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              대분류             중분류             소분류         브랜드  2022-01-01  \\\n",
       "0  B002-C001-0002  B002-C002-0007  B002-C003-0038  B002-00001         0.0   \n",
       "1  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002         0.0   \n",
       "2  B002-C001-0003  B002-C002-0008  B002-C003-0044  B002-00002         0.0   \n",
       "\n",
       "   2022-01-02  2022-01-03  2022-01-04  2022-01-05  2022-01-06  ...  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "2         0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "   2023-03-26  2023-03-27  2023-03-28  2023-03-29  2023-03-30  2023-03-31  \\\n",
       "0         0.0         0.0         0.0    0.000000    0.000000    0.000000   \n",
       "1         0.0         0.0         0.0    0.111111    0.333333    0.222222   \n",
       "2         0.0         0.0         0.0    0.000000    0.000000    0.000000   \n",
       "\n",
       "   2023-04-01  2023-04-02  2023-04-03  2023-04-04  \n",
       "0         0.0         0.0    0.000000         0.0  \n",
       "1         0.0         0.0    0.222222         0.0  \n",
       "2         0.0         0.0    0.000000         0.0  \n",
       "\n",
       "[3 rows x 463 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scale = origin_train.copy()\n",
    "\n",
    "train_scale.drop(['ID', '제품'], axis = 1, inplace = True)\n",
    "scaler = IndividualMinMaxScaler()\n",
    "train_scale.iloc[:, 4:] = scaler.fit_transform(origin_train)\n",
    "print(min(train_scale.iloc[:, 6]), max(train_scale.iloc[:, 6]))\n",
    "train_scale.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder.fit(train_scale[col])\n",
    "    train_scale[col] = label_encoder.transform(train_scale[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29026263bb794343add21a9d3b774ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edd43e546994dc6bb66f5e87c3c40ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4487336, 90, 5)\n",
      "(4487336, 21)\n",
      "(1121834, 90, 5)\n",
      "(1121834, 21)\n",
      "(15890, 90, 5)\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = make_train_data(train_scale)\n",
    "test_input = make_predict_data(train_scale)\n",
    "\n",
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]\n",
    "\n",
    "print(train_input.shape)\n",
    "print(train_target.shape)\n",
    "print(val_input.shape)\n",
    "print(val_target.shape)\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualMinMaxScaler:\n",
    "    def __get_min_val(self, df, date_cols):\n",
    "        df_mins = df[date_cols].min(axis=1).to_numpy()\n",
    "        return df_mins\n",
    "\n",
    "    def __get_max_val(self, df, date_cols):\n",
    "        df_maxs = df[date_cols].max(axis=1).to_numpy()\n",
    "        return df_maxs\n",
    "\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        date_cols = [col for col in df.columns  # 일자 변수들만 Scale하기\n",
    "                     if col.startswith(\"2\")]\n",
    "\n",
    "        self.min_val = self.__get_min_val(df, date_cols)\n",
    "        self.max_val = self.__get_max_val(df, date_cols)\n",
    "        denom = self.max_val - self.min_val\n",
    "        self.denom = np.where(denom==0, 1, denom)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        date_cols = [col for col in df.columns\n",
    "                     if col.startswith(\"2\")]\n",
    "        return df[date_cols] \\\n",
    "            .apply(lambda x: (x-self.min_val)/self.denom)\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_sfa(pred, df):\n",
    "    pred_length = pred.shape[1] - 1\n",
    "    true = df.iloc[:, -pred_length:].reset_index() \\\n",
    "        .rename(columns={\"index\": \"ID\"})\n",
    "\n",
    "    main_id = {}\n",
    "    for main_cat in df[\"대분류\"].unique():\n",
    "        main_id[main_cat] = df.query(\"대분류==@main_cat\")[\"ID\"].to_list()\n",
    "\n",
    "    psfa = []\n",
    "    for main_cat in main_id.keys():\n",
    "        indices = true[\"ID\"].isin(main_id[main_cat])\n",
    "\n",
    "        true_arr = true[indices].iloc[:, 1:].to_numpy()\n",
    "        pred_arr = pred[indices].iloc[:, 1:].to_numpy()\n",
    "\n",
    "        eps = np.ones((true_arr.shape)) / 1e8\n",
    "\n",
    "        true_sum = true_arr.sum(axis=0)\n",
    "        true_sum = np.stack([true_sum]*len(true_arr)) + eps\n",
    "        true_rate = true_arr / true_sum\n",
    "\n",
    "        abs_error = np.abs(true_arr - pred_arr)\n",
    "        denom = np.maximum(true_arr, pred_arr+eps)\n",
    "        \n",
    "        score = 1 - (1 / true_arr.shape[1]\n",
    "                     * (abs_error / denom) * true_rate).sum()\n",
    "        psfa.append(score)\n",
    "        print(main_cat, score)\n",
    "\n",
    "    return np.mean(psfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PsfaLoss(nn.Module):\n",
    "    def __init__(self, scaler, df):\n",
    "        super().__init__()\n",
    "        self.scaler = scaler\n",
    "        self.main_cats = df.groupby(\"대분류\")[\"ID\"].unique().values\n",
    "    \n",
    "    def forward(self, pred, true):\n",
    "        # pred: [batch_size, length, products(15890)]\n",
    "        pred = pred * torch.tensor(self.scaler.denom) \\\n",
    "            + torch.tensor(self.scaler.min_val)\n",
    "        true = true * torch.tensor(self.scaler.denom) \\\n",
    "            + torch.tensor(self.scaler.min_val)\n",
    "\n",
    "        L1scaled = torch.abs(true-pred) / torch.maximum(pred, true+1e-8)\n",
    "        \n",
    "        rate = torch.zeros_like(true)\n",
    "        for i in range(len(self.main_cats)):\n",
    "            rate[:, :, self.main_cats[i]] = \\\n",
    "                true[:, :, self.main_cats[i]] \\\n",
    "                / (true[:, :, self.main_cats[i]].sum(dim=-1, keepdim=True) + 1e-8) \\\n",
    "                / len(self.main_cats)\n",
    "        return (L1scaled * rate).sum() / (true.shape[0] * true.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLinear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "train_dataset = CustomDataset(train_input[:-int(data_len*0.2)], train_target[:-int(data_len*0.2)])\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(train_input[-int(data_len*0.2):], train_target[-int(data_len*0.2):])\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Engineering한 Data\n",
    "\n",
    "# train_input = np.load(LOADPATH + 'train_input.npy')\n",
    "# train_target = np.load(LOADPATH + 'train_target.npy')\n",
    "# test_input = np.load(LOADPATH + 'test_input.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size = 25, stride = 1):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \t# [BATCH SIZE, SEQ_LEN, CHANNEL]\n",
    "        # padding on the both ends of time series\n",
    "\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x # [BATCH SIZE, SEQ_LEN, CHANNEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input.shape = (data_num, window_size, feature_size)\n",
    "# \n",
    "\n",
    "class DLinear(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Decomposition-Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size = CFG['TRAIN_WINDOW_SIZE'], forcast_size=CFG['PREDICT_SIZE'], kernel_size = 25, individual = False, feature_size=1):\n",
    "        super(DLinear, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.forcast_size = forcast_size\n",
    "\n",
    "        # Decomposition Kernel Size\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "        self.individual = individual\n",
    "        self.channels = feature_size\n",
    "        \n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = torch.nn.ModuleList().to(device)\n",
    "            self.Linear_Trend = torch.nn.ModuleList().to(device)\n",
    "            \n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Trend.append(torch.nn.Linear(self.window_size, self.forcast_size).to(device))\n",
    "                self.Linear_Trend[i].weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size])).to(device)\n",
    "\n",
    "                # Use this two lines if you want to visualize the weights\n",
    "                self.Linear_Seasonal.append(torch.nn.Linear(self.window_size, self.forcast_size))\n",
    "                self.Linear_Seasonal[i].weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "\n",
    "        else:\n",
    "            self.Linear_Trend = torch.nn.Linear(self.window_size, self.forcast_size).to(device)\n",
    "            self.Linear_Trend.weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "\n",
    "            # Use this two lines if you want to visualize the weights\n",
    "            self.Linear_Seasonal = torch.nn.Linear(self.window_size,  self.forcast_size).to(device)\n",
    "            self.Linear_Seasonal.weight = torch.nn.Parameter((1/self.window_size)*torch.ones([self.forcast_size, self.window_size]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        trend_init, seasonal_init = self.decompsition(x)\n",
    "        trend_init, seasonal_init = trend_init.permute(0,2,1), seasonal_init.permute(0,2,1)\n",
    "\n",
    "        if self.individual:\n",
    "            trend_output = torch.zeros([trend_init.size(0), trend_init.size(1), self.forcast_size], dtype=trend_init.dtype).to(trend_init.device)\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0), seasonal_init.size(1), self.forcast_size], dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "            \n",
    "            for idx in range(self.channels):\n",
    "                trend_output[:, idx, :] = self.Linear_Trend[idx](trend_init[:, idx, :]).to(device)\n",
    "                seasonal_output[:, idx, :] = self.Linear_Seasonal[idx](seasonal_init[:, idx, :]).to(device)\n",
    "\n",
    "        else:\n",
    "            trend_output = self.Linear_Trend(trend_init).to(device)\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init).to(device)\n",
    "        \n",
    "        x = seasonal_output + trend_output\n",
    "        \n",
    "        return x.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_li = []\n",
    "val_loss_li = []\n",
    "test_loss_li = []\n",
    "epoch = 10\n",
    "lr = 1e-6\n",
    "\n",
    "DLinear_model = DLinear(\n",
    "    window_size = CFG['TRAIN_WINDOW_SIZE'],\n",
    "    forcast_size=CFG['PREDICT_SIZE'],\n",
    "    kernel_size = 25,\n",
    "    individual = False,\n",
    "    feature_size = train_dataset.X.shape[2]\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(DLinear_model.parameters(), lr = lr)\n",
    "best_loss = 9999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f8c2c7e294451fb2b5a8864f479203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9780795e72f43bcb9fd36f975cf87b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5efaf7b1840436a9003d22a513384e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.9823] Val Loss : [0.1922]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedf88869565429b9c733c97161a7308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9ddddaec2e40b9adc7fd986f4e3ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2] Train Loss : [0.9651] Val Loss : [0.1912]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fff9cd24104ca08ec161052689d973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f052211a622049cca4cd69e8ff677e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3] Train Loss : [0.9571] Val Loss : [0.1905]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3809fffb71d64a868eb87ed818a525d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d75b1df9866443894ff41565a3e8214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4] Train Loss : [0.9515] Val Loss : [0.1900]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9209f161eab474b98f820c89501bcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6e3903cb9b42b8a4e53cd5a4d4ad0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5] Train Loss : [0.9477] Val Loss : [0.1896]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d76cec1bc5471f982feb8828008804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb7226ed8a44839af5352f8762bd98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6] Train Loss : [0.9443] Val Loss : [0.1892]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bca33b1eee84f21b37b9835cd8b4847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84952b7e2ac141bc8dbac0ba92a760ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7] Train Loss : [0.9418] Val Loss : [0.1888]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633df666ffa49708fff2a85ab05851f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8a70fb67844fbd956ae6cd6d0a13ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8] Train Loss : [0.9397] Val Loss : [0.1886]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4e85b797434f9cb4f94793461af266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00e2b66c89b4368a6ef8501f4711adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9] Train Loss : [0.9379] Val Loss : [0.1883]\n",
      "Model Saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b54db4148d4402a566865c5005205d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766f24c52ce84079bbb81ee567a0ee96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10] Train Loss : [0.9363] Val Loss : [0.1881]\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, 11)):\n",
    "    loss_list = []\n",
    "    DLinear_model.train()\n",
    "\n",
    "    for data, target in tqdm(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = DLinear_model(data)\n",
    "        loss = criterion(output, target.unsqueeze(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())    \n",
    "\n",
    "    train_loss_li.append(np.mean(loss_list))\n",
    "\n",
    "    DLinear_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(iter(val_loader)):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = DLinear_model(data)\n",
    "            valid_loss = criterion(output, target.unsqueeze(-1))\n",
    "\n",
    "            val_loss_li.append(valid_loss.item())\n",
    "\n",
    "    print(f'Epoch : [{epoch}] Train Loss : [{np.mean(loss_list):.4f}] Val Loss : [{np.mean(val_loss_li):.4f}]')\n",
    "\n",
    "    if valid_loss < best_loss:\n",
    "        # torch.save(DLinear_model, 'DLinear_model.pth')\n",
    "        best_loss = valid_loss\n",
    "        dlinear_best_epoch = epoch\n",
    "        dlinear_best_train_loss = np.mean(loss_list)\n",
    "        dlinear_best_valid_loss = np.mean(valid_loss.item())\n",
    "        print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590c8d1d204c4d82b903e8d42a2edb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1430011 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m time_slide_df(test_df_enc, window_size, \u001b[39m0\u001b[39;49m, date, target)\n",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m, in \u001b[0;36mtime_slide_df\u001b[0;34m(df, window_size, forcast_size, date, target)\u001b[0m\n\u001b[1;32m     24\u001b[0m date_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, df_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39mwindow_size\u001b[39m-\u001b[39mforcast_size\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m---> 27\u001b[0m     x \u001b[39m=\u001b[39m df_\u001b[39m.\u001b[39;49mloc[idx:idx\u001b[39m+\u001b[39;49mwindow_size\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, target]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(window_size, \u001b[39m1\u001b[39m)       \u001b[39m# 90일치 판매량\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     y \u001b[39m=\u001b[39m df_\u001b[39m.\u001b[39mloc[idx\u001b[39m+\u001b[39mwindow_size:idx\u001b[39m+\u001b[39mwindow_size\u001b[39m+\u001b[39mforcast_size\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, target]\u001b[39m.\u001b[39mvalues      \u001b[39m# 21일치 판매량 (target)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     date_ \u001b[39m=\u001b[39m df_\u001b[39m.\u001b[39mloc[idx\u001b[39m+\u001b[39mwindow_size:idx\u001b[39m+\u001b[39mwindow_size\u001b[39m+\u001b[39mforcast_size\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, date]\u001b[39m.\u001b[39mvalues    \u001b[39m# 날짜\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/aimer/lib/python3.8/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/aimer/lib/python3.8/site-packages/pandas/core/indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/anaconda3/envs/aimer/lib/python3.8/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/anaconda3/envs/aimer/lib/python3.8/site-packages/pandas/core/indexing.py:1299\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex)):\n\u001b[1;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_iterable(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "time_slide_df(test_df_enc, window_size, 0, date, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_dataset \u001b[39m=\u001b[39m CustomDataset(test_input, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mBATCH_SIZE\u001b[39m\u001b[39m'\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_input' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(test_input, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5830b69a287436a8db3928b38a2f8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X in tqdm(iter(test_loader)):\n",
    "        X = X.to(device)\n",
    "\n",
    "        output = DLinear_model(X)\n",
    "        # 모델 출력인 output을 CPU로 이동하고 numpy 배열로 변환\n",
    "        output = output.cpu().numpy()\n",
    "            \n",
    "        predictions.extend(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01744074, 0.03097999, 0.0335838 , ..., 0.03069846, 0.03145359,\n",
       "        0.0432485 ],\n",
       "       [0.0475485 , 0.04547943, 0.06210718, ..., 0.05769744, 0.05753664,\n",
       "        0.06239583],\n",
       "       [0.00410482, 0.00686081, 0.00874485, ..., 0.01962999, 0.02041792,\n",
       "        0.02107154],\n",
       "       ...,\n",
       "       [0.00361981, 0.00678486, 0.0090176 , ..., 0.01900744, 0.01884934,\n",
       "        0.0187877 ],\n",
       "       [0.10489664, 0.08854678, 0.06268504, ..., 0.04553596, 0.04296607,\n",
       "        0.04558872],\n",
       "       [0.00367289, 0.00620643, 0.00812227, ..., 0.01828414, 0.01888015,\n",
       "        0.01933588]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2023-04-05</th>\n",
       "      <th>2023-04-06</th>\n",
       "      <th>2023-04-07</th>\n",
       "      <th>2023-04-08</th>\n",
       "      <th>2023-04-09</th>\n",
       "      <th>2023-04-10</th>\n",
       "      <th>2023-04-11</th>\n",
       "      <th>2023-04-12</th>\n",
       "      <th>2023-04-13</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-04-16</th>\n",
       "      <th>2023-04-17</th>\n",
       "      <th>2023-04-18</th>\n",
       "      <th>2023-04-19</th>\n",
       "      <th>2023-04-20</th>\n",
       "      <th>2023-04-21</th>\n",
       "      <th>2023-04-22</th>\n",
       "      <th>2023-04-23</th>\n",
       "      <th>2023-04-24</th>\n",
       "      <th>2023-04-25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017441</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>0.033584</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.017369</td>\n",
       "      <td>0.030133</td>\n",
       "      <td>0.039729</td>\n",
       "      <td>0.050789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024773</td>\n",
       "      <td>0.025457</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.044702</td>\n",
       "      <td>0.053858</td>\n",
       "      <td>0.051216</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>0.030698</td>\n",
       "      <td>0.031454</td>\n",
       "      <td>0.043249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047549</td>\n",
       "      <td>0.045479</td>\n",
       "      <td>0.062107</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.051628</td>\n",
       "      <td>0.053787</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>0.069866</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>0.057448</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>0.072180</td>\n",
       "      <td>0.078113</td>\n",
       "      <td>0.073422</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.057697</td>\n",
       "      <td>0.057537</td>\n",
       "      <td>0.062396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>0.013447</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.020418</td>\n",
       "      <td>0.021072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.012041</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.016808</td>\n",
       "      <td>0.017362</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.019336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.016228</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>0.012639</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>0.018428</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.017992</td>\n",
       "      <td>0.021929</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.030493</td>\n",
       "      <td>0.026933</td>\n",
       "      <td>0.022235</td>\n",
       "      <td>0.019752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>15885</td>\n",
       "      <td>-0.012594</td>\n",
       "      <td>-0.006994</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.035730</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.029446</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054787</td>\n",
       "      <td>0.040858</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.053982</td>\n",
       "      <td>0.058707</td>\n",
       "      <td>0.041828</td>\n",
       "      <td>0.020154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>15886</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>0.035373</td>\n",
       "      <td>0.039040</td>\n",
       "      <td>0.037397</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>0.036263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035879</td>\n",
       "      <td>0.028235</td>\n",
       "      <td>0.028987</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>0.046752</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>0.051612</td>\n",
       "      <td>0.042663</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.032476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>15887</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.010578</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.018788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15888</th>\n",
       "      <td>15888</td>\n",
       "      <td>0.104897</td>\n",
       "      <td>0.088547</td>\n",
       "      <td>0.062685</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.045335</td>\n",
       "      <td>0.041895</td>\n",
       "      <td>0.044290</td>\n",
       "      <td>0.048533</td>\n",
       "      <td>0.053316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045509</td>\n",
       "      <td>0.043063</td>\n",
       "      <td>0.045253</td>\n",
       "      <td>0.049968</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.051415</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>0.045589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>15889</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.012041</td>\n",
       "      <td>0.012788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.015574</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.016808</td>\n",
       "      <td>0.017362</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.018880</td>\n",
       "      <td>0.019336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15890 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  2023-04-05  2023-04-06  2023-04-07  2023-04-08  2023-04-09  \\\n",
       "0          0    0.017441    0.030980    0.033584    0.022638    0.013365   \n",
       "1          1    0.047549    0.045479    0.062107    0.057356    0.051628   \n",
       "2          2    0.004105    0.006861    0.008745    0.009651    0.010667   \n",
       "3          3    0.003673    0.006206    0.008122    0.009051    0.009837   \n",
       "4          4    0.003771    0.009547    0.016228    0.020355    0.017405   \n",
       "...      ...         ...         ...         ...         ...         ...   \n",
       "15885  15885   -0.012594   -0.006994    0.011467    0.035730    0.045422   \n",
       "15886  15886    0.026855    0.035373    0.039040    0.037397    0.029384   \n",
       "15887  15887    0.003620    0.006785    0.009018    0.010113    0.010578   \n",
       "15888  15888    0.104897    0.088547    0.062685    0.051906    0.045335   \n",
       "15889  15889    0.003673    0.006206    0.008122    0.009051    0.009837   \n",
       "\n",
       "       2023-04-10  2023-04-11  2023-04-12  2023-04-13  ...  2023-04-16  \\\n",
       "0        0.017369    0.030133    0.039729    0.050789  ...    0.024773   \n",
       "1        0.053787    0.059697    0.069866    0.076554  ...    0.057258   \n",
       "2        0.011621    0.012523    0.013447    0.014126  ...    0.015659   \n",
       "3        0.010603    0.011314    0.012041    0.012788  ...    0.014462   \n",
       "4        0.012639    0.010349    0.011653    0.016810  ...    0.022983   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "15885    0.029446    0.006225   -0.005651   -0.000057  ...    0.054787   \n",
       "15886    0.022271    0.021897    0.027614    0.036263  ...    0.035879   \n",
       "15887    0.010671    0.010959    0.011858    0.013141  ...    0.015151   \n",
       "15888    0.041895    0.044290    0.048533    0.053316  ...    0.045509   \n",
       "15889    0.010603    0.011314    0.012041    0.012788  ...    0.014462   \n",
       "\n",
       "       2023-04-17  2023-04-18  2023-04-19  2023-04-20  2023-04-21  2023-04-22  \\\n",
       "0        0.025457    0.034845    0.044702    0.053858    0.051216    0.037808   \n",
       "1        0.057448    0.063567    0.072180    0.078113    0.073422    0.064179   \n",
       "2        0.016318    0.017067    0.017778    0.018308    0.018709    0.019102   \n",
       "3        0.014986    0.015574    0.016197    0.016808    0.017362    0.017839   \n",
       "4        0.018428    0.016688    0.017992    0.021929    0.027962    0.030493   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "15885    0.040858    0.018686    0.005335    0.008692    0.030258    0.053982   \n",
       "15886    0.028235    0.028987    0.036884    0.046752    0.053272    0.051612   \n",
       "15887    0.014812    0.015046    0.015891    0.017131    0.018109    0.018912   \n",
       "15888    0.043063    0.045253    0.049968    0.054557    0.055319    0.051415   \n",
       "15889    0.014986    0.015574    0.016197    0.016808    0.017362    0.017839   \n",
       "\n",
       "       2023-04-23  2023-04-24  2023-04-25  \n",
       "0        0.030698    0.031454    0.043249  \n",
       "1        0.057697    0.057537    0.062396  \n",
       "2        0.019630    0.020418    0.021072  \n",
       "3        0.018284    0.018880    0.019336  \n",
       "4        0.026933    0.022235    0.019752  \n",
       "...           ...         ...         ...  \n",
       "15885    0.058707    0.041828    0.020154  \n",
       "15886    0.042663    0.034726    0.032476  \n",
       "15887    0.019007    0.018849    0.018788  \n",
       "15888    0.045536    0.042966    0.045589  \n",
       "15889    0.018284    0.018880    0.019336  \n",
       "\n",
       "[15890 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.array(predictions)\n",
    "\n",
    "submit = pd.read_csv(PATH + '/sample_submission.csv') # submit은 15690개 상품 / 예측은 15682개 상품\n",
    "submit.iloc[:, 1:] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(PATH + 'Dlinear_submit_1.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
